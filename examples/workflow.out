Using TensorFlow backend.
Warning: Master yarn-client is deprecated since 2.0. Please use master "yarn" with specified deploy mode instead.
Ivy Default Cache set to: /home/ubuntu/.ivy2/cache
The jars for the packages stored in: /home/ubuntu/.ivy2/jars
:: loading settings :: url = jar:file:/home/ubuntu/Download/spark-2.1.1/assembly/target/scala-2.11/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
com.databricks#spark-csv_2.10 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent;1.0
	confs: [default]
	found com.databricks#spark-csv_2.10;1.4.0 in central
	found org.apache.commons#commons-csv;1.1 in central
	found com.univocity#univocity-parsers;1.5.1 in central
:: resolution report :: resolve 297ms :: artifacts dl 7ms
	:: modules in use:
	com.databricks#spark-csv_2.10;1.4.0 from central in [default]
	com.univocity#univocity-parsers;1.5.1 from central in [default]
	org.apache.commons#commons-csv;1.1 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent
	confs: [default]
	0 artifacts copied, 3 already retrieved (0kB/9ms)
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
17/05/19 06:14:52 WARN spark.SparkConf: spark.master yarn-client is deprecated in Spark 2.0+, please instead use "yarn" with specified deploy mode.
17/05/19 06:14:55 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
17/05/19 06:15:00 WARN yarn.Client: Same path resource file:/home/ubuntu/.ivy2/jars/com.databricks_spark-csv_2.10-1.4.0.jar added multiple times to distributed cache.
17/05/19 06:15:00 WARN yarn.Client: Same path resource file:/home/ubuntu/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar added multiple times to distributed cache.
17/05/19 06:15:00 WARN yarn.Client: Same path resource file:/home/ubuntu/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar added multiple times to distributed cache.
[Stage 2:>                                                          (0 + 2) / 2]                                                                                17/05/19 06:15:31 WARN util.Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[Stage 4:>                                                          (0 + 6) / 6][Stage 4:=========>                                                 (1 + 5) / 6][Stage 4:===================>                                       (2 + 4) / 6][Stage 4:=============================>                             (3 + 3) / 6][Stage 4:=======================================>                   (4 + 2) / 6]                                                                                [Stage 6:>                                                          (0 + 6) / 6][Stage 6:=========>                                                 (1 + 5) / 6]                                                                                [Stage 8:===================>                                       (2 + 4) / 6]                                                                                [Stage 10:>                                                         (0 + 6) / 6][Stage 10:======================================>                   (4 + 2) / 6]                                                                                17/05/19 06:15:43 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 13.0 (TID 40, slave, executor 3): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 163, in main
    func, profiler, deserializer, serializer = read_command(pickleSer, infile)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 54, in read_command
    command = serializer._read_with_length(file)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 169, in _read_with_length
    return self.loads(obj)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 454, in loads
    return pickle.loads(obj)
ImportError: No module named distkeras.utils

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

17/05/19 06:15:44 ERROR scheduler.TaskSetManager: Task 0 in stage 13.0 failed 4 times; aborting job
Number of desired executors: 6
Number of desired cores / executor: 2
Total number of workers: 12
root
 |-- EventId: integer (nullable = true)
 |-- DER_mass_MMC: double (nullable = true)
 |-- DER_mass_transverse_met_lep: double (nullable = true)
 |-- DER_mass_vis: double (nullable = true)
 |-- DER_pt_h: double (nullable = true)
 |-- DER_deltaeta_jet_jet: double (nullable = true)
 |-- DER_mass_jet_jet: double (nullable = true)
 |-- DER_prodeta_jet_jet: double (nullable = true)
 |-- DER_deltar_tau_lep: double (nullable = true)
 |-- DER_pt_tot: double (nullable = true)
 |-- DER_sum_pt: double (nullable = true)
 |-- DER_pt_ratio_lep_tau: double (nullable = true)
 |-- DER_met_phi_centrality: double (nullable = true)
 |-- DER_lep_eta_centrality: double (nullable = true)
 |-- PRI_tau_pt: double (nullable = true)
 |-- PRI_tau_eta: double (nullable = true)
 |-- PRI_tau_phi: double (nullable = true)
 |-- PRI_lep_pt: double (nullable = true)
 |-- PRI_lep_eta: double (nullable = true)
 |-- PRI_lep_phi: double (nullable = true)
 |-- PRI_met: double (nullable = true)
 |-- PRI_met_phi: double (nullable = true)
 |-- PRI_met_sumet: double (nullable = true)
 |-- PRI_jet_num: integer (nullable = true)
 |-- PRI_jet_leading_pt: double (nullable = true)
 |-- PRI_jet_leading_eta: double (nullable = true)
 |-- PRI_jet_leading_phi: double (nullable = true)
 |-- PRI_jet_subleading_pt: double (nullable = true)
 |-- PRI_jet_subleading_eta: double (nullable = true)
 |-- PRI_jet_subleading_phi: double (nullable = true)
 |-- PRI_jet_all_pt: double (nullable = true)
 |-- Weight: double (nullable = true)
 |-- Label: string (nullable = true)

root
 |-- EventId: integer (nullable = true)
 |-- DER_mass_MMC: double (nullable = true)
 |-- DER_mass_transverse_met_lep: double (nullable = true)
 |-- DER_mass_vis: double (nullable = true)
 |-- DER_pt_h: double (nullable = true)
 |-- DER_deltaeta_jet_jet: double (nullable = true)
 |-- DER_mass_jet_jet: double (nullable = true)
 |-- DER_prodeta_jet_jet: double (nullable = true)
 |-- DER_deltar_tau_lep: double (nullable = true)
 |-- DER_pt_tot: double (nullable = true)
 |-- DER_sum_pt: double (nullable = true)
 |-- DER_pt_ratio_lep_tau: double (nullable = true)
 |-- DER_met_phi_centrality: double (nullable = true)
 |-- DER_lep_eta_centrality: double (nullable = true)
 |-- PRI_tau_pt: double (nullable = true)
 |-- PRI_tau_eta: double (nullable = true)
 |-- PRI_tau_phi: double (nullable = true)
 |-- PRI_lep_pt: double (nullable = true)
 |-- PRI_lep_eta: double (nullable = true)
 |-- PRI_lep_phi: double (nullable = true)
 |-- PRI_met: double (nullable = true)
 |-- PRI_met_phi: double (nullable = true)
 |-- PRI_met_sumet: double (nullable = true)
 |-- PRI_jet_num: integer (nullable = true)
 |-- PRI_jet_leading_pt: double (nullable = true)
 |-- PRI_jet_leading_eta: double (nullable = true)
 |-- PRI_jet_leading_phi: double (nullable = true)
 |-- PRI_jet_subleading_pt: double (nullable = true)
 |-- PRI_jet_subleading_eta: double (nullable = true)
 |-- PRI_jet_subleading_phi: double (nullable = true)
 |-- PRI_jet_all_pt: double (nullable = true)
 |-- Weight: double (nullable = true)
 |-- Label: string (nullable = true)
 |-- features: vector (nullable = true)
 |-- features_normalized: vector (nullable = true)

Traceback (most recent call last):
  File "workflow_jobs_test.py", line 147, in <module>
    dataset = transformer.transform(dataset)
  File "/home/ubuntu/anaconda2/lib/python2.7/site-packages/distkeras/transformers.py", line 299, in transform
    return dataframe.rdd.map(self._transform).toDF()
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/sql/session.py", line 57, in toDF
    return sparkSession.createDataFrame(self, schema, sampleRatio)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/sql/session.py", line 524, in createDataFrame
    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/sql/session.py", line 364, in _createFromRDD
    struct = self._inferSchema(rdd, samplingRatio)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/sql/session.py", line 335, in _inferSchema
    first = rdd.first()
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/rdd.py", line 1360, in first
    rs = self.take(1)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/rdd.py", line 1342, in take
    res = self.context.runJob(self, takeUpToNumLeft, p)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/context.py", line 968, in runJob
    port = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)
  File "/home/ubuntu/Download/spark-2.1.1/python/py4j/java_gateway.py", line 1133, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/home/ubuntu/Download/spark-2.1.1/python/py4j/protocol.py", line 319, in get_return_value
    format(target_id, ".", name), value)
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 13.0 failed 4 times, most recent failure: Lost task 0.3 in stage 13.0 (TID 43, slave, executor 2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 163, in main
    func, profiler, deserializer, serializer = read_command(pickleSer, infile)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 54, in read_command
    command = serializer._read_with_length(file)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 169, in _read_with_length
    return self.loads(obj)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 454, in loads
    return pickle.loads(obj)
ImportError: No module named distkeras.utils

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:441)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 163, in main
    func, profiler, deserializer, serializer = read_command(pickleSer, infile)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 54, in read_command
    command = serializer._read_with_length(file)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 169, in _read_with_length
    return self.loads(obj)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 454, in loads
    return pickle.loads(obj)
ImportError: No module named distkeras.utils

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

Using TensorFlow backend.
Warning: Master yarn-client is deprecated since 2.0. Please use master "yarn" with specified deploy mode instead.
Ivy Default Cache set to: /home/ubuntu/.ivy2/cache
The jars for the packages stored in: /home/ubuntu/.ivy2/jars
:: loading settings :: url = jar:file:/home/ubuntu/Download/spark-2.1.1/assembly/target/scala-2.11/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
com.databricks#spark-csv_2.10 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent;1.0
	confs: [default]
	found com.databricks#spark-csv_2.10;1.4.0 in central
	found org.apache.commons#commons-csv;1.1 in central
	found com.univocity#univocity-parsers;1.5.1 in central
:: resolution report :: resolve 313ms :: artifacts dl 7ms
	:: modules in use:
	com.databricks#spark-csv_2.10;1.4.0 from central in [default]
	com.univocity#univocity-parsers;1.5.1 from central in [default]
	org.apache.commons#commons-csv;1.1 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent
	confs: [default]
	0 artifacts copied, 3 already retrieved (0kB/9ms)
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
17/05/19 06:36:44 WARN spark.SparkConf: spark.master yarn-client is deprecated in Spark 2.0+, please instead use "yarn" with specified deploy mode.
17/05/19 06:36:47 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
17/05/19 06:36:51 WARN yarn.Client: Same path resource file:/home/ubuntu/.ivy2/jars/com.databricks_spark-csv_2.10-1.4.0.jar added multiple times to distributed cache.
17/05/19 06:36:51 WARN yarn.Client: Same path resource file:/home/ubuntu/.ivy2/jars/org.apache.commons_commons-csv-1.1.jar added multiple times to distributed cache.
17/05/19 06:36:51 WARN yarn.Client: Same path resource file:/home/ubuntu/.ivy2/jars/com.univocity_univocity-parsers-1.5.1.jar added multiple times to distributed cache.
[Stage 2:>                                                          (0 + 2) / 2][Stage 2:=============================>                             (1 + 1) / 2]                                                                                17/05/19 06:37:23 WARN util.Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[Stage 4:>                                                          (0 + 6) / 6][Stage 4:===================>                                       (2 + 4) / 6][Stage 4:=============================>                             (3 + 3) / 6][Stage 4:=================================================>         (5 + 1) / 6]                                                                                [Stage 6:=========>                                                 (1 + 5) / 6]                                                                                [Stage 8:=================================================>         (5 + 1) / 6]                                                                                [Stage 10:>                                                         (0 + 6) / 6][Stage 10:===================>                                      (2 + 4) / 6]                                                                                17/05/19 06:37:33 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 13.0 (TID 40, slave, executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 163, in main
    func, profiler, deserializer, serializer = read_command(pickleSer, infile)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 54, in read_command
    command = serializer._read_with_length(file)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 169, in _read_with_length
    return self.loads(obj)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 454, in loads
    return pickle.loads(obj)
ImportError: No module named distkeras.utils

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

17/05/19 06:37:34 ERROR scheduler.TaskSetManager: Task 0 in stage 13.0 failed 4 times; aborting job
Number of desired executors: 6
Number of desired cores / executor: 2
Total number of workers: 12
root
 |-- EventId: integer (nullable = true)
 |-- DER_mass_MMC: double (nullable = true)
 |-- DER_mass_transverse_met_lep: double (nullable = true)
 |-- DER_mass_vis: double (nullable = true)
 |-- DER_pt_h: double (nullable = true)
 |-- DER_deltaeta_jet_jet: double (nullable = true)
 |-- DER_mass_jet_jet: double (nullable = true)
 |-- DER_prodeta_jet_jet: double (nullable = true)
 |-- DER_deltar_tau_lep: double (nullable = true)
 |-- DER_pt_tot: double (nullable = true)
 |-- DER_sum_pt: double (nullable = true)
 |-- DER_pt_ratio_lep_tau: double (nullable = true)
 |-- DER_met_phi_centrality: double (nullable = true)
 |-- DER_lep_eta_centrality: double (nullable = true)
 |-- PRI_tau_pt: double (nullable = true)
 |-- PRI_tau_eta: double (nullable = true)
 |-- PRI_tau_phi: double (nullable = true)
 |-- PRI_lep_pt: double (nullable = true)
 |-- PRI_lep_eta: double (nullable = true)
 |-- PRI_lep_phi: double (nullable = true)
 |-- PRI_met: double (nullable = true)
 |-- PRI_met_phi: double (nullable = true)
 |-- PRI_met_sumet: double (nullable = true)
 |-- PRI_jet_num: integer (nullable = true)
 |-- PRI_jet_leading_pt: double (nullable = true)
 |-- PRI_jet_leading_eta: double (nullable = true)
 |-- PRI_jet_leading_phi: double (nullable = true)
 |-- PRI_jet_subleading_pt: double (nullable = true)
 |-- PRI_jet_subleading_eta: double (nullable = true)
 |-- PRI_jet_subleading_phi: double (nullable = true)
 |-- PRI_jet_all_pt: double (nullable = true)
 |-- Weight: double (nullable = true)
 |-- Label: string (nullable = true)

root
 |-- EventId: integer (nullable = true)
 |-- DER_mass_MMC: double (nullable = true)
 |-- DER_mass_transverse_met_lep: double (nullable = true)
 |-- DER_mass_vis: double (nullable = true)
 |-- DER_pt_h: double (nullable = true)
 |-- DER_deltaeta_jet_jet: double (nullable = true)
 |-- DER_mass_jet_jet: double (nullable = true)
 |-- DER_prodeta_jet_jet: double (nullable = true)
 |-- DER_deltar_tau_lep: double (nullable = true)
 |-- DER_pt_tot: double (nullable = true)
 |-- DER_sum_pt: double (nullable = true)
 |-- DER_pt_ratio_lep_tau: double (nullable = true)
 |-- DER_met_phi_centrality: double (nullable = true)
 |-- DER_lep_eta_centrality: double (nullable = true)
 |-- PRI_tau_pt: double (nullable = true)
 |-- PRI_tau_eta: double (nullable = true)
 |-- PRI_tau_phi: double (nullable = true)
 |-- PRI_lep_pt: double (nullable = true)
 |-- PRI_lep_eta: double (nullable = true)
 |-- PRI_lep_phi: double (nullable = true)
 |-- PRI_met: double (nullable = true)
 |-- PRI_met_phi: double (nullable = true)
 |-- PRI_met_sumet: double (nullable = true)
 |-- PRI_jet_num: integer (nullable = true)
 |-- PRI_jet_leading_pt: double (nullable = true)
 |-- PRI_jet_leading_eta: double (nullable = true)
 |-- PRI_jet_leading_phi: double (nullable = true)
 |-- PRI_jet_subleading_pt: double (nullable = true)
 |-- PRI_jet_subleading_eta: double (nullable = true)
 |-- PRI_jet_subleading_phi: double (nullable = true)
 |-- PRI_jet_all_pt: double (nullable = true)
 |-- Weight: double (nullable = true)
 |-- Label: string (nullable = true)
 |-- features: vector (nullable = true)
 |-- features_normalized: vector (nullable = true)

Traceback (most recent call last):
  File "workflow_jobs_test.py", line 148, in <module>
    dataset = transformer.transform(dataset)
  File "/home/ubuntu/anaconda2/lib/python2.7/site-packages/distkeras/transformers.py", line 299, in transform
    return dataframe.rdd.map(self._transform).toDF()
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/sql/session.py", line 57, in toDF
    return sparkSession.createDataFrame(self, schema, sampleRatio)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/sql/session.py", line 524, in createDataFrame
    rdd, schema = self._createFromRDD(data.map(prepare), schema, samplingRatio)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/sql/session.py", line 364, in _createFromRDD
    struct = self._inferSchema(rdd, samplingRatio)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/sql/session.py", line 335, in _inferSchema
    first = rdd.first()
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/rdd.py", line 1360, in first
    rs = self.take(1)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/rdd.py", line 1342, in take
    res = self.context.runJob(self, takeUpToNumLeft, p)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/context.py", line 968, in runJob
    port = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)
  File "/home/ubuntu/Download/spark-2.1.1/python/py4j/java_gateway.py", line 1133, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/home/ubuntu/Download/spark-2.1.1/python/py4j/protocol.py", line 319, in get_return_value
    format(target_id, ".", name), value)
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 13.0 failed 4 times, most recent failure: Lost task 0.3 in stage 13.0 (TID 43, slave, executor 1): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 163, in main
    func, profiler, deserializer, serializer = read_command(pickleSer, infile)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 54, in read_command
    command = serializer._read_with_length(file)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 169, in _read_with_length
    return self.loads(obj)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 454, in loads
    return pickle.loads(obj)
ImportError: No module named distkeras.utils

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:441)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 163, in main
    func, profiler, deserializer, serializer = read_command(pickleSer, infile)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/worker.py", line 54, in read_command
    command = serializer._read_with_length(file)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 169, in _read_with_length
    return self.loads(obj)
  File "/home/ubuntu/Download/spark-2.1.1/python/pyspark/serializers.py", line 454, in loads
    return pickle.loads(obj)
ImportError: No module named distkeras.utils

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

