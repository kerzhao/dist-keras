{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development and Evaluation\n",
    "\n",
    "**Joeri Hermans** (Technical Student, IT-DB-SAS, CERN)             \n",
    "*Departement of Knowledge Engineering*         \n",
    "*Maastricht University, The Netherlands*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is dedicated to the development and evaluation of a Keras model based on a large [preprocessed dataset](https://github.com/JoeriHermans/dist-keras/blob/master/examples/data_preprocessing.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from distkeras.transformers import LabelIndexTransformer\n",
    "from distkeras.predictors import ModelPredictor\n",
    "from distkeras.trainers import SingleTrainer\n",
    "from distkeras.trainers import AEASGD\n",
    "from distkeras.trainers import DOWNPOUR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Configuration and Preparation\n",
    "\n",
    "Edit the variables in the cell below. If you are running Spark in local mode, please set the `local` flag to true and adjust the resources you wish to use on your local machine. The same goes for the case when you are running Spark 2.0 and higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify these variables according to your needs.\n",
    "application_name = \"Distributed Deep Learning: Analysis\"\n",
    "using_spark_2 = False\n",
    "local = False\n",
    "if local:\n",
    "    # Tell master to use local resources.\n",
    "    master = \"local[*]\"\n",
    "    num_cores = 3\n",
    "    num_executors = 1\n",
    "else:\n",
    "    # Tell master to use YARN.\n",
    "    master = \"yarn-client\"\n",
    "    num_executors = 8\n",
    "    num_cores = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of desired executors: 8\n",
      "Number of desired cores / executor: 2\n",
      "Total number of workers: 16\n"
     ]
    }
   ],
   "source": [
    "# This variable is derived from the number of cores and executors, and will be used to assign the number of model trainers.\n",
    "num_workers = num_executors * num_cores\n",
    "\n",
    "print(\"Number of desired executors: \" + `num_executors`)\n",
    "print(\"Number of desired cores / executor: \" + `num_cores`)\n",
    "print(\"Total number of workers: \" + `num_workers`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", application_name)\n",
    "conf.set(\"spark.master\", master)\n",
    "conf.set(\"spark.executor.cores\", `num_cores`)\n",
    "conf.set(\"spark.executor.instances\", `num_executors`)\n",
    "conf.set(\"spark.executor.memory\",\"2g\")\n",
    "conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\");\n",
    "\n",
    "# Check if the user is running Spark 2.0 +\n",
    "if using_spark_2:\n",
    "    sc = SparkSession.builder.config(conf=conf) \\\n",
    "            .appName(application_name) \\\n",
    "            .getOrCreate()\n",
    "else:\n",
    "    # Create the Spark context.\n",
    "    #sc = SparkContext(conf=conf)\n",
    "    sc.conf = conf\n",
    "    # Add the missing imports\n",
    "    from pyspark import SQLContext\n",
    "    sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "After the Spark Context (or Spark Session if you are using Spark 2.0) has been set up, we can start reading the preprocessed dataset from storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if we are using Spark 2.0\n",
    "if using_spark_2:\n",
    "    reader = sc\n",
    "else:\n",
    "    reader = sqlContext\n",
    "# Read the dataset.\n",
    "raw_dataset = reader.read.parquet(\"data/processed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features_normalized: vector (nullable = true)\n",
      " |-- label_index: double (nullable = true)\n",
      " |-- newlabel: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the schema.\n",
    "raw_dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the dataset from storage, we will extract several metrics such as `nb_features`, which basically is the number of input neurons, and `nb_classes`, which is the number of classes (signal and background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 30\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "nb_features = len(raw_dataset.select(\"features_normalized\").take(1)[0][\"features_normalized\"])\n",
    "nb_classes = len(raw_dataset.select(\"newlabel\").take(1)[0][\"newlabel\"])\n",
    "\n",
    "print(\"Number of features: \" + str(nb_features))\n",
    "print(\"Number of classes: \" + str(nb_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we split up the dataset for training and testing purposes, and fetch some additional statistics on the number of training and testing instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features_normalized: vector, label_index: double, newlabel: array<double>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, we create a trainingset and a testset.\n",
    "(training_set, test_set) = raw_dataset.randomSplit([0.7, 0.3])\n",
    "training_set.cache()\n",
    "test_set.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testset instances: 163\n",
      "Number of trainingset instances: 391\n",
      "Total number of instances: 554\n"
     ]
    }
   ],
   "source": [
    "# Distribute the training and test set to the workers.\n",
    "test_set = test_set.repartition(num_workers)\n",
    "training_set = training_set.repartition(num_workers)\n",
    "\n",
    "num_test_set = test_set.count()\n",
    "num_training_set = training_set.count()\n",
    "\n",
    "print(\"Number of testset instances: \" + str(num_test_set))\n",
    "print(\"Number of trainingset instances: \" + str(num_training_set))\n",
    "print(\"Total number of instances: \" + str(num_test_set + num_training_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_shape=(nb_features,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               15500     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 1002      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 517,502\n",
      "Trainable params: 517,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = 'adagrad'\n",
    "loss = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    global test_set\n",
    "\n",
    "    metric_name = \"f1\"\n",
    "    evaluator = MulticlassClassificationEvaluator(metricName=metric_name, predictionCol=\"prediction_index\", labelCol=\"label_index\")\n",
    "    # Clear the prediction column from the testset.\n",
    "    test_set = test_set.select(\"features_normalized\", \"newlabel\", \"label_index\")\n",
    "    # Apply a prediction from a trained model.\n",
    "    predictor = ModelPredictor(keras_model=trained_model, features_col=\"features_normalized\")\n",
    "    test_set = predictor.predict(test_set)\n",
    "    # Transform the prediction vector to an indexed label.\n",
    "    index_transformer = LabelIndexTransformer(output_dim=nb_classes)\n",
    "    test_set = index_transformer.transform(test_set)\n",
    "    # Store the F1 score of the SingleTrainer.\n",
    "    score = evaluator.evaluate(test_set)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "time_spent = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation\n",
    "\n",
    "In the next sections we train and evaluate the models trained by different (distributed) optimizers.\n",
    "\n",
    "### Single Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = SingleTrainer(keras_model=model, loss=loss, worker_optimizer=optimizer, \n",
    "                        features_col=\"features_normalized\", num_epoch=1, batch_size=64)\n",
    "trained_model = trainer.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent (SingleTrainer): 3.4336349964141846 seconds.\n",
      "F1 (SingleTrainer): 0.5638766519823789\n"
     ]
    }
   ],
   "source": [
    "# Fetch the training time.\n",
    "dt = trainer.get_training_time()\n",
    "print(\"Time spent (SingleTrainer): \" + `dt` + \" seconds.\")\n",
    "\n",
    "# Evaluate the model.\n",
    "score = evaluate(trained_model)\n",
    "print(\"F1 (SingleTrainer): \" + `score`)\n",
    "\n",
    "# Store the training metrics.\n",
    "results['single'] = score\n",
    "time_spent['single'] = dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous EASGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = AEASGD(keras_model=model, worker_optimizer=optimizer, loss=loss, num_workers=num_workers, batch_size=64,\n",
    "                 features_col=\"features_normalized\", num_epoch=1, communication_window=32, \n",
    "                 rho=5.0, learning_rate=0.1)\n",
    "trainer.set_parallelism_factor(1)\n",
    "trained_model = trainer.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent (AEASGD): 6.031414031982422 seconds.\n",
      "F1 (AEASGD): 0.5638766519823789\n"
     ]
    }
   ],
   "source": [
    "# Fetch the training time.\n",
    "dt = trainer.get_training_time()\n",
    "print(\"Time spent (AEASGD): \" + `dt` + \" seconds.\")\n",
    "\n",
    "# Evaluate the model.\n",
    "score = evaluate(trained_model)\n",
    "print(\"F1 (AEASGD): \" + `score`)\n",
    "\n",
    "# Store the training metrics.\n",
    "results['aeasgd'] = score\n",
    "time_spent['aeasgd'] = dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOWNPOUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = DOWNPOUR(keras_model=model, worker_optimizer=optimizer, loss=loss, num_workers=num_workers,\n",
    "                   batch_size=64, communication_window=5, num_epoch=1,\n",
    "                   features_col=\"features_normalized\")\n",
    "trainer.set_parallelism_factor(1)\n",
    "trained_model = trainer.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent (DOWNPOUR): 6.7732579708099365 seconds.\n",
      "F1 (DOWNPOUR): 0.5638766519823789\n"
     ]
    }
   ],
   "source": [
    "# Fetch the training time.\n",
    "dt = trainer.get_training_time()\n",
    "print(\"Time spent (DOWNPOUR): \" + `dt` + \" seconds.\")\n",
    "\n",
    "# Evaluate the model.\n",
    "score = evaluate(trained_model)\n",
    "print(\"F1 (DOWNPOUR): \" + `score`)\n",
    "\n",
    "# Store the training metrics.\n",
    "results['downpour'] = score\n",
    "time_spent['downpour'] = dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plots below, the distributed optimizers finish a single epoch ~7 times however. However, for this, the distributed optimizers use 16 times the amount of resources. However, a not very descriptive measure since some of jobs are scheduled on the same machines, some machines have a higher load etc. Nevertheless, the statistical performance of the optimizers is within 1% error. Which means that the classifiers would have near-identical performance. Furthermore, it is our guess that the statistical performance of the distributed optimizers can be improved by adding adaptive learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEjCAYAAAA/ugbCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFQRJREFUeJzt3XmUZWV97vHvAx0EGhQMHSIgNhcHghgECoMDhigagyYO\nVwWWiiRcO2oE0cQb1NwLyTIuCMQbjBrTMUoMhNwwKALKcJFBUYZugowCBlExCk1EZFDR7t/9Y++G\nsujhdFedc7rq/X7W6tV7Ovv9VZ3hqf3uvd+TqkKS1K6Nxl2AJGm8DAJJapxBIEmNMwgkqXEGgSQ1\nziCQpMYZBJrVkhya5BUzuL9Mmt4uybvWsO1+Sd6xlv2dlGSLfvr0Adr3PamRmzfuAqSZlGQf4O39\n7MeAFwDnAa8GlgMX9MsuBQ6lew98FbgTeA9weZLjqmo5sAmwfZJfA44GvgV8uqpunNTkAUm2Bzap\nqj9O8jbg6cBWwP8Cng28L8m/ALsmOQY4oV/3OGBj4EjgMuBs4IvAVTP8a5HWyL8+NNccDizq//0R\ncAmwH/B4YJt++hLg3cC9wDJgj/6xX6mqD/YhMNmv9NueOiUEAK6sqvcCj0vyZOAQ4D7gh8CewLXA\nB6vqBuCmqjoG2BdY2G+zBbA98FBVHVtVhoBGziMCzTUBatL0v9N96N9G9xf+BPChfvrEqroXum4e\nug/wx6iqS5PcDhyWZPeq+qc1tP/d/sOefr+vmryr/v+NgMur6sOTtltl29IoGASaC97enye4HfgI\n8PF++ceqanmSLem6fzYFdqmqFUmOA/42yV3AHcD1q9t5kt8Cfhd4InDhlNW/keRY4CdV9Z0kVyX5\nW7oQ+mTf7l8l+ThwV7/tB4BXJzmergvp8Cnt/XNVvWm9fxvSOopjDUlS2zxHIEmNMwgkqXEGgSQ1\nziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMM\nAklqnEEgSY0zCCSpcQaBJDVuaEGQ5JNJ7k5yw6RlT0xyYZLb+v+3Hlb7kqTBDPOI4CTgZVOWHQVc\nVFVPAy7q5yVJY5SqGt7Ok4XAOVW1Wz9/C7BfVX0vyZOAS6rqGUMrQJK0VvNG3N62VfW9fvr7wLar\n2zDJImARwPz58/faZZddRlCeJM0dS5cuvaeqFqxtu1EHwSOqqpKs9nCkqhYDiwEmJiZqyZIlI6tN\nkuaCJN8aZLtRXzV0V98lRP//3SNuX5I0xaiD4HPAm/vpNwNnjbh9SdIUw7x89FTgq8AzktyZ5DDg\nWOAlSW4D9u/nJUljNLRzBFV18GpWvXhYbUqS1p13FktS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTG\nGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxB\nIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS\n1DiDQJIaZxBIUuMMAklq3FiCIMm7ktyY5IYkpybZdBx1SJLGEARJtgeOACaqajdgY+CgUdchSeqM\nq2toHrBZknnA5sB/jqkOSWreyIOgqr4LnAB8G/gecF9VXTDqOiRJnXF0DW0NvBLYCdgOmJ/kjavY\nblGSJUmWLFu2bNRlSlIzxtE1tD/wzapaVlU/A84Enjd1o6paXFUTVTWxYMGCkRcpSa0YRxB8G9gn\nyeZJArwYuHkMdUiSGM85giuB04FrgOv7GhaPug5JUmfeOBqtqqOBo8fRtiTpF3lnsSQ1ziCQpMYZ\nBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEg\nSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJaty8cRcgafZbeNS54y5hzrrj2JcPvQ2P\nCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUuLEE\nQZKtkpye5OtJbk7y3HHUIUka3+ijJwLnVdVrk2wCbD6mOiSpeSMPgiRPAF4IHApQVQ8DD4+6DklS\nZxxHBDsBy4BPJdkdWAq8s6oenLxRkkXAIoAdd9xxvRtznPThGcU46ZKGbxznCOYBewJ/V1V7AA8C\nR03dqKoWV9VEVU0sWLBg1DVKUjPGEQR3AndW1ZX9/Ol0wSBJGoORB0FVfR/4TpJn9IteDNw06jok\nSZ2BzhEkmQ/8uKpWJHk6sAvwhar62Xq2ezhwSn/F0O3A76/nfiRJ0zToyeLLgH2TbA1cAFwNHAi8\nYX0araprgYn1eawkaWYN2jWUqnoIeA3wsap6HfDM4ZUlSRqVgYOgv/v3DcDK6zE3Hk5JkqRRGjQI\njgTeC3ymqm5M8t+Ai4dXliRpVAY6R1BVlwKXTpq/HThiWEVJkkZnjUGQ5GygVre+qn5vxiuSJI3U\n2o4ITuj/fw3wq8DJ/fzBwF3DKkqSNDprDIK+S4gkf11Vky/3PDvJkqFWJkkaiUFPFs/vTxADkGQn\nYP5wSpIkjdKgN5S9C7gkye1AgKcAfzi0qiRJIzPoVUPnJXka3dASAF+vqp8OryxJ0qisy/cR7AUs\n7B+zexKq6tNDqUqSNDKDDjr3z8DOwLXA8n5xAQaBJM1ygx4RTAC7VtVq7ymQJM1Og141dAPdfQSS\npDlm0COCbYCbklwFPHKS2DuLJWn2GzQIjhlmEZKk8Rl40Lkk2wJ794uuqqq7h1eWJGlUBjpHkOT1\nwFXA64DXA1cmee0wC5MkjcagXUPvB/ZeeRSQZAHw/4DTh1WYJGk0Br1qaKMpXUH/tQ6PlSRtwAY9\nIjgvyfnAqf38gcAXhlOSJGmUBj1Z/J4krwFe0C9aXFWfGV5ZkqRRGXSIiZ2Az1fVmf38ZkkWVtUd\nwyxOkjR8g/bznwasmDS/vF8mSZrlBg2CeVX18MqZfnqT4ZQkSRqlQYNgWZJHhpNI8krgnuGUJEka\npUGvGnorcEqSj9INP30ncMjQqpIkjcygVw39B7BPki36+QeGWpUkaWQGHWJi2yT/CJxWVQ8k2TXJ\nYUOuTZI0AoOeIzgJOB/Yrp+/FThyGAVJkkZr0CDYpqr+jf4S0qr6OY9+ZaUkaRYbNAgeTPLLdCeK\nSbIPcN/QqpIkjcygVw29G/gcsHOSy4EFgMNQS9IcsMYjgiR7J/nVqroG+E3gfXRfVXkB3SWkkqRZ\nbm1dQ38PrLyj+Hl030vwUeBeYPF0Gk6ycZJ/T3LOdPYjSZqetXUNbVxVP+inD6QbdfQM4Iwk106z\n7XcCNwOPn+Z+JEnTsLYjgo2TrAyLFwNfnLRu0PMLj5FkB+DlwCfWdx+SpJmxtg/zU4FLk9wD/Bj4\nEkCSpzK9q4b+BvifwJbT2IckaQasMQiq6i+TXAQ8CbigqqpftRFw+Po0mOQVwN1VtTTJfmvYbhGw\nCGDHHXdcn6YkSQNYa/dOVV2ximW3TqPN5wO/l+QAYFPg8UlOrqo3TmljMf0J6YmJiXrsbiRJM2Hk\nX0BfVe+tqh2qaiFwEPDFqSEgSRqdkQeBJGnDst5X/syEqroEuGScNUhS6zwikKTGGQSS1DiDQJIa\nZxBIUuMMAklqnEEgSY0zCCSpcWO9j0BalYVHnTvuEuasO459+bhL0AbIIwJJapxBIEmNMwgkqXEG\ngSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBI\nUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEjD4Ik\nT05ycZKbktyY5J2jrkGS9Kh5Y2jz58AfV9U1SbYElia5sKpuGkMtktS8kR8RVNX3quqafvp+4GZg\n+1HXIUnqjPUcQZKFwB7AlatYtyjJkiRLli1bNurSJKkZYwuCJFsAZwBHVtWPpq6vqsVVNVFVEwsW\nLBh9gZLUiLEEQZJfoguBU6rqzHHUIEnqjOOqoQD/CNxcVR8adfuSpF80jiOC5wNvAl6U5Nr+3wFj\nqEOSxBguH62qLwMZdbuSpFXzzmJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwC\nSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCk\nxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqc\nQSBJjRtLECR5WZJbknwjyVHjqEGS1Bl5ECTZGPgo8DvArsDBSXYddR2SpM44jgieA3yjqm6vqoeB\nfwVeOYY6JEmMJwi2B74zaf7OfpkkaQzmjbuA1UmyCFjUzz6Q5JZx1jNC2wD3jLuIQeS4cVewQZg1\nzxf4nPVaes6eMshG4wiC7wJPnjS/Q7/sF1TVYmDxqIraUCRZUlUT465Dg/H5mn18zh5rHF1DVwNP\nS7JTkk2Ag4DPjaEOSRJjOCKoqp8neQdwPrAx8MmqunHUdUiSOmM5R1BVnwc+P462Z4HmusNmOZ+v\n2cfnbIpU1bhrkCSNkUNMSFLjDII5JMkxSf5k3HXMFUk+sb53vSdZmOSGma6pRb6uh2+DvY9AGreq\n+h/jrkGzT5J5VfXzcdexLjwimEFJPptkaZIb+xviSPLSJF9Nck2S05Js0S//30muTnJDksVJ0i8/\nIslNSa5L8q/9sgVJLuz3+4kk30qyTb/u/UluTfJl4Blj+tFnvSTzk5yb5Gv9c3JgkkuSTPTrH0jy\nl/36K5Js2y/fuZ+/PskHkjywin1vnOT4/vm+Lskfjvrnm21W9bpO8uz+d31dks8k2TrJryRZ2q/f\nPUkl2bGf/48kmyc5KcmHk3wlye1JXtuv3y/JZf3zfkuSjyfZqF93cP+c3pA8ekvX5Oc3yWuTnNRP\nn9Q//krgr0b0a5oxBsHM+oOq2guYAI7oPyz+DNi/qvYElgDv7rf9SFXtXVW7AZsBr+iXHwXsUVW/\nDry1X3Y08MWqeiZwOrDyhb4X3X0YzwYOAPYe9g84h70M+M+q2r1/Ts6bsn4+cEVV7Q5cBrylX34i\ncGJVPYtuuJRVOQy4r6r2pnuO3pJkpxn/CeaINbyuPw38af/euB44uqruBjZN8nhgX7r32L5JngLc\nXVUP9Y99EvACuvfZsZOaew5wON0AmDsDr0myHXAc8KK+hr2TvGqA0ncAnldV717rlhsYg2BmHZHk\na8AVdHdPv4XuBXZ5kmuBN/PoLd+/leTKJNfTveCe2S+/DjglyRuBlYeXL6AbnI+qOg+4t1++L/CZ\nqnqoqn6EN+ZNx/XAS5Icl2TfqrpvyvqHgXP66aXAwn76ucBp/fS/rGbfLwUO6V8DVwK/DDxtpgqf\ng1b1up4PbFVVl/bb/BPwwn76K8Dz+/kP9v/vC3xp0j4/W1UrquomYNtJy6/qB8BcDpxK917bG7ik\nqpb1XTynTGprTU7r9zPreI5ghiTZD9gfeG5VPZTkEuBrwIVVdfCUbTcFPgZMVNV3khwDbNqvfjnd\ni+53gfcnedZofoK2VdWtSfak+wv0A0kumrLJz+rRa62Xs27vnQCHV9X5M1CqHusyug/+pwBnAX8K\nFHDupG1+Omk6k6anXj+/tuvpJ6/fdMq6B9da6QbKI4KZ8wTg3j4EdgH2oXuhPD/JU+GRfuin8+gL\n6J7+nMHKPsuNgCdX1cV0L+YnAFsAlwOv77d5KbB1//jLgFcl2SzJlnThofXQdwc8VFUnA8cDew74\n0CuA/95PH7Sabc4H3pbkl/q2np5k/nTqneNW9bp+ELg3yb79Nm8CVh4dfAl4I3BbVa0AfkAX6F8e\noK3npBvuZiPgwP4xVwG/mWSbdN+fcvCktu5K8mv99q+e9k+6gfCIYOacB7w1yc3ALXQfEMuAQ4FT\nkzyu3+7P+r8+/wG4Afg+3fhL0A25cXKSJ9D91fLhqvphkj/v9/Em4Kv9Y+6vqmuS/F+6I4+7J+1H\n6+5ZwPFJVgA/A94GnDDA446ke87eT/camNqlBPAJuq6ka5KE7nUxSJ9zk9bwun4z8PEkmwO3A7/f\nb39H/3u9rN/uy8AOVXUva3c18BHgqcDFdF1SK9J9c+LFdO/Dc6vqrH77o+i6CJfRnY/YYlo/7AbC\nO4tngT5ElvfjND0X+Luqeva46xL0H0o/rqpKchBwcFX5RUuzQN+d+ydV9Yq1bTvXeUQwO+wI/Ft/\nOPowj16xovHbC/hI/xfpD4E/GHM90jrziECSGufJYklqnEEgSY0zCCSpcQaB5qwkOyQ5K8lt/bgz\nJ6b7etTVbb9VkrdPmt8uyenr2OZfJNl/OnVLo+bJYs1J/VU8V9Jdavup/sagxcAPquo9q3nMQuCc\nfqyhscksHL1Ss5uXj2quehHwk6r6FEBVLU/yLuCbSb4J/DbdndvbAydX1Z/TDUa2cz8m0IXAR+mD\nIcmhdDeBzacbJ+gEYBO6O1x/ChxQVT/oR6M8B7iD7kYy6G4U3K271SA79/tdADwEvKWqvt4/7ifA\nHnRjU51FN6AddMMavLCq7p/5X5NkEGjueibd4HCPqKofJfk23ev+OcBudB/GVyc5l+6u0d1W3qzX\nHyFMthvdB/WmwDfoRsLcI8n/AQ4B/mZSW0voRq4kyfE8OprpYuCtVXVbkt+gG3PqRf26laNXLk9y\nNvBHVXV5PwzJT6b5+5BWyyBQqy6sqv8CSHIm3aiTn13LYy7u/yq/P8l9wNn98uuBX1/VA5IcSDdu\n0Uv7D/TnAad1PVcAPG7S5pNHr7wc+FCSU4Azq2p1Q1xL02YQaK66iX4wv5X6Met3pBvee11HnYRf\nHMFyxaT5FazivZRkN+AYum6d5f2d4T9cw/Agj4xeWVXH9kcpB9B1Ff12VX19gBqldeZVQ5qrLgI2\nT3IIdN8SBvw1cBJdd9BLkjwxyWZ0ff+XA/cDW85E40m2ohvf/pCqWgZd1xTdOYrX9dskye6refzO\nVXV9VR1HNzDaLjNRl7QqBoHmpP67A14NvC7JbcCtdP3s7+s3uQo4g+6LgM6oqiV9V9Hl6b6e8Php\nlvBKuvHx/yHJtf0JaIA3AIf1X2B0Y7/dqhzZ13Ed3WioX5hmPdJqefmomtNfATRRVe8Ydy3ShsAj\nAklqnEcEktQ4jwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4/4/7fVoQ0o2O+YAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f61204d6690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the time.\n",
    "fig = plt.figure()\n",
    "st = fig.suptitle(\"Lower is better.\", fontsize=\"x-small\")\n",
    "\n",
    "plt.bar(range(len(time_spent)), time_spent.values(), align='center')\n",
    "plt.xticks(range(len(time_spent)), time_spent.keys())\n",
    "plt.xlabel(\"Optimizers\")\n",
    "plt.ylabel(\"Seconds\")\n",
    "plt.ylim([0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEjCAYAAAAhczZxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFsFJREFUeJzt3Xu4XXV95/H3hwTk4gUd0jISEIpYBpCLHlNFsYyKpUqL\nnaFD6KjVdmSgReulM6XVofTmo4PTqRpsnhRRO1BpRQrIReSxIoiCCYiBgGiKVkJtiagBBMTAd/5Y\nK2H3eJLzOyTrnBPO+/U858m6/H5rf3fWPvtz1lp7/XaqCkmSJrPdTBcgSdo2GBiSpCYGhiSpiYEh\nSWpiYEiSmhgYkqQmBobmhCRvSHJMP71/ktOTPDPJ26a4ne1Gpn85yRGbaXt6koMm2d75/b97J3lf\nw+NnKvVKW9P8mS5AmkE7AHsk2RH4MPBN4BeBnwdeDbwQeCrwQeA1wDOArwAf6fs/A3g0ya8BRwLr\ngHdV1Y9GHuPkPmS+BPwN8GfAk4B5wFnAAUlOB1YDhyc5BfgU8A4gwD8CFwLn9ss/DKzdyv8PUhMD\nQ3PJb/VHGbsCXxtZfhTwmar6WJLD+mWnAJ8FHgIW9cv+tqqunWC7+wIrgYvGhQXA31XV55NcQPdG\nvzdwG/As4PvArVV1epK9gUOrakmS9wIP9j/PpQuMW6vqPY//qUtbzsDQXPKhqrokyf7A4k202TD0\nwYNVdfqGhf1RwLoJO1T9SZJDgDOS/K+q+sYmtrsdcG1VfWBkuxse79GRttsB/6+qVvZt9t7UY0vT\nycCQ4ErgrCTPBp5Jd1RxTpJldH/lX7q5zklOBPaje9O/Z9zq45McD1wEXAEsTXIG3VHOm4F/TfIe\n4N3As5O8HVgCvDvJd4D7gI+NPNZC4Ler6ve38DlLUxbHkpIgyTuA3YF7q+pPZroeaTYyMCRJTfxY\nrSSpiYEhSWpiYEiSmhgYkqQmBoYkqYmBIUlqYmBIkpoYGJKkJgaGJKmJgSFJamJgSJKaGBiSpCYG\nhiSpiYEhSWpiYEiSmhgYkqQmBoYkqYmBIUlqMmhgJDk6ye1JVic5dRNtjkxyU5JVST4/lb6SpOkz\n2Hd6J5kHfB04ClgDLAdOqKpbR9rsCnwROLqqvp3kp6rq7pa+kqTpNeQRxiJgdVXdUVUPA+cBx45r\n82vABVX1bYCqunsKfSVJ02j+gNveA7hzZH4N8HPj2jwH2D7JVcBTgPdX1V839gUgyYnAiQC77LLL\n8/fff/+tUrwkzQU33HDDd6tqQUvbIQOj9fGfD7wc2An4UpLrprKBqloGLAMYGxurFStWbPUiJemJ\nKsk/tbYdMjDuAvYcmV/YLxu1Brinqn4I/DDJ1cAh/fLJ+kqSptGQ1zCWA/sl2SfJDsBi4OJxbS4C\nXpJkfpKd6U473dbYV5I0jQY7wqiq9UlOAa4A5gFnV9WqJCf165dW1W1JPg2sBB4FzqqqWwAm6jtU\nrZKkyQ32sdqZ4DUMSZqaJDdU1VhLW+/0liQ1MTAkSU0MDElSEwNDktTEwJAkNTEwJElNDAxJUhMD\nQ5LUxMCQJDUxMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElSEwNDktTEwJAkNTEwJElNDAxJUhMD\nQ5LUxMCQJDUxMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElSEwNDktTEwJAkNTEwJElNDAxJUhMD\nQ5LUxMCQJDUxMCRJTQYNjCRHJ7k9yeokp06w/sgk65Lc1P+cNrLubUlWJbklyceT7DhkrZKkzRss\nMJLMA84EfhE4ADghyQETNL2mqg7tf/6477sH8BZgrKoOAuYBi4eqVZI0uSGPMBYBq6vqjqp6GDgP\nOHYK/ecDOyWZD+wM/PMANUqSGg0ZGHsAd47Mr+mXjXd4kpVJLk9yIEBV3QW8D/g28B1gXVV9ZsBa\nJUmTmOmL3jcCe1XVwcAHgQsBkjyd7mhkH+CZwC5JXjvRBpKcmGRFkhVr166dprIlae4ZMjDuAvYc\nmV/YL9uoqu6tqvv76cuA7ZPsBrwC+GZVra2qHwMXAIdP9CBVtayqxqpqbMGCBUM8D0kSwwbGcmC/\nJPsk2YHuovXFow2S7J4k/fSivp576E5FvTDJzv36lwO3DVirJGkS84facFWtT3IKcAXdp5zOrqpV\nSU7q1y8FjgNOTrIeeBBYXFUFXJ/kfLpTVuuBrwDLhqpVkjS5dO/PTwxjY2O1YsWKmS5DkrYZSW6o\nqrGWtjN90VuStI0wMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElSEwNDktTEwJAkNTEwJElNDAxJ\nUhMDQ5LUxMCQJDUxMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElSEwNDktTEwJAkNTEwJElNDAxJ\nUhMDQ5LUxMCQJDUxMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU3mz3QBs8Xep1460yU8YX3rPa/e6tt0\nfw1niP0F7rMhDbXPxvMIQ5LUxMCQJDUxMCRJTQwMSVKTQQMjydFJbk+yOsmpE6w/Msm6JDf1P6eN\nrNs1yflJvpbktiQvGrJWSdLmDfYpqSTzgDOBo4A1wPIkF1fVreOaXlNVx0ywifcDn66q45LsAOw8\nVK2SpMkNeYSxCFhdVXdU1cPAecCxLR2TPA14KfBhgKp6uKp+MFilkqRJDRkYewB3jsyv6ZeNd3iS\nlUkuT3Jgv2wfYC3wkSRfSXJWkl0mepAkJyZZkWTF2rVrt+oTkCQ9ZqYvet8I7FVVBwMfBC7sl88H\nngf8ZVUdBvwQ+IlrIABVtayqxqpqbMGCBdNRsyTNSUMGxl3AniPzC/tlG1XVvVV1fz99GbB9kt3o\njkbWVNX1fdPz6QJEkjRDhgyM5cB+SfbpL1ovBi4ebZBk9yTppxf19dxTVf8C3JnkZ/umLwfGXyyX\nJE2jwT4lVVXrk5wCXAHMA86uqlVJTurXLwWOA05Osh54EFhcVdVv4s3AuX3Y3AG8cahaJUmTG3Tw\nwf4002Xjli0dmV4CLNlE35uAsSHrkyS1m+mL3pKkbYSBIUlqYmBIkpoYGJKkJgaGJKmJgSFJamJg\nSJKaGBiSpCYGhiSpiYEhSWpiYEiSmhgYkqQmBoYkqcnjDowk+2/NQiRJs9uWHGF8ZqtVIUma9Tb7\nfRhJPrCpVcCuW78cSdJsNdkXKL0ReAfwownWnbD1y5EkzVaTBcZy4Jaq+uL4FUlOH6QiSdKsNFlg\nHAc8NNGKqtpn65cjSZqtJrvo/eSqemBaKpEkzWqTBcaFGyaSfHLgWiRJs9hkgZGR6Z8ZshBJ0uw2\nWWDUJqYlSXPMZBe9D0lyL92Rxk79NP18VdVTB61OkjRrbDYwqmredBUiSZrdHHxQktTEwJAkNTEw\nJElNDAxJUhMDQ5LUxMCQJDUxMCRJTQwMSVITA0OS1GTQwEhydJLbk6xOcuoE649Msi7JTf3PaePW\nz0vylSSXDFmnJGlyk40l9bglmQecCRwFrAGWJ7m4qm4d1/SaqjpmE5v5HeA2wDGrJGmGDXmEsQhY\nXVV3VNXDwHnAsa2dkywEXg2cNVB9kqQpGDIw9gDuHJlf0y8b7/AkK5NcnuTAkeV/AfxP4NEBa5Qk\nNZrpi943AntV1cHAB+m/4S/JMcDdVXXDZBtIcmKSFUlWrF27dthqJWkOGzIw7gL2HJlf2C/bqKru\nrar7++nLgO2T7Aa8GPjlJN+iO5X1siTnTPQgVbWsqsaqamzBggUDPA1JEgwbGMuB/ZLsk2QHYDFw\n8WiDJLsnST+9qK/nnqr6/apaWFV79/3+oapeO2CtkqRJDPYpqapan+QU4ApgHnB2Va1KclK/filw\nHHBykvXAg8DiqvKrYCVpFhosMGDjaabLxi1bOjK9BFgyyTauAq4aoDxJ0hTM9EVvSdI2wsCQJDUx\nMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElSEwNDktTEwJAkNTEwJElNDAxJUhMDQ5LUxMCQJDUx\nMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElSEwNDktTEwJAkNTEwJElNDAxJUhMDQ5LUxMCQJDUx\nMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElSEwNDktTEwJAkNTEwJElNBg2MJEcnuT3J6iSnTrD+\nyCTrktzU/5zWL98zyeeS3JpkVZLfGbJOSdLk5g+14STzgDOBo4A1wPIkF1fVreOaXlNVx4xbth54\nR1XdmOQpwA1JrpygryRpmgx5hLEIWF1Vd1TVw8B5wLEtHavqO1V1Yz99H3AbsMdglUqSJjVkYOwB\n3Dkyv4aJ3/QPT7IyyeVJDhy/MsnewGHA9RM9SJITk6xIsmLt2rVbXrUkaUIzfdH7RmCvqjoY+CBw\n4ejKJE8GPgm8tarunWgDVbWsqsaqamzBggWDFyxJc9WQgXEXsOfI/MJ+2UZVdW9V3d9PXwZsn2Q3\ngCTb04XFuVV1wYB1SpIaDBkYy4H9kuyTZAdgMXDxaIMkuydJP72or+eeftmHgduq6s8HrFGS1Giw\nT0lV1fokpwBXAPOAs6tqVZKT+vVLgeOAk5OsBx4EFldVJXkJ8Drg5iQ39Zv8g/4oRJI0AwYLDNh4\nmumyccuWjkwvAZZM0O8LQIasTZI0NTN90VuStI0wMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElS\nEwNDktTEwJAkNTEwJElNDAxJUhMDQ5LUxMCQJDUxMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElS\nEwNDktTEwJAkNTEwJElNDAxJUhMDQ5LUxMCQJDUxMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU0MDElS\nEwNDktTEwJAkNTEwJElNBg2MJEcnuT3J6iSnTrD+yCTrktzU/5zW2leSNL3mD7XhJPOAM4GjgDXA\n8iQXV9Wt45peU1XHPM6+kqRpMuQRxiJgdVXdUVUPA+cBx05DX0nSAIYMjD2AO0fm1/TLxjs8ycok\nlyc5cIp9JUnTZLBTUo1uBPaqqvuTvAq4ENhvKhtIciJwYj97f5Lbt3KNs9FuwHdnuohWee9MVzAr\nbDP7zP210VzZZ89qbThkYNwF7Dkyv7BftlFV3TsyfVmSDyXZraXvSL9lwLKtVfS2IMmKqhqb6TrU\nzn227XGf/aQhT0ktB/ZLsk+SHYDFwMWjDZLsniT99KK+nnta+kqSptdgRxhVtT7JKcAVwDzg7Kpa\nleSkfv1S4Djg5CTrgQeBxVVVwIR9h6pVkjS5dO/P2pYkObE/FadthPts2+M++0kGhiSpiUODSJKa\nGBhzUJLTk/zuTNfxRJHkrCQHPM6+eye5ZWvXNNf4mp4eM30fhrTNq6r/NtM1aNuSZH5VrZ/pOqbK\nI4wZkOTCJDckWdXfeEiSVyb5UpIbk3wiyZP75aclWZ7kliTLRj6G/JYkt/Z3yZ/XL1uQ5Mp+u2cl\n+af+vhaSvDPJ15N8AfjZGXrq27wkuyS5NMlX+31yfJKrkoz16+9P8mf9+uuS/HS/fN9+/uYkf5rk\n/gm2PS/JGf3+Xpnkv0/389uWTPSaTnJo//+8MsnfJ3l6kp9KckO//pAklWSvfv4fk+yc5KNJPpDk\ni0nuSHJcv/7IJFf3+/z2JEuTbNevO6Hfn7ckj906N7pvkxyX5KP99Ef7/tcD/3ua/pu2KgNjZvxG\nVT0fGAPe0r+pvAt4RVU9D1gBvL1vu6SqXlBVBwE7ARsGajwVOKyqDgZO6pf9IfAPVXUgcD6w4Zfi\n+XT3shwKvAp4wdBP8AnsaOCfq+qQfp98etz6XYDrquoQ4GrgTf3y9wPvr6rn0g11M5HfBNZV1Qvo\n9tGbkuyz1Z/BE8BmXtN/Dfxe/3txM/CHVXU3sGOSpwJH0P1+HZHkWcDdVfVA3/ffAy+h+x17z8jD\nLQLeDBwA7Av8pyTPBN4LvKyv4QVJXtNQ+kLg8Kp6+6QtZyEDY2a8JclXgevo7mh/E92L8dokNwG/\nzmO36//HJNcnuZnuxblhvK2VwLlJXgtsOLR9Cd1AjVTVp4Hv98uPAP6+qh7o7673JsjH72bgqCTv\nTXJEVa0bt/5h4JJ++gZg7376RcAn+um/2cS2Xwm8vn8NXA/8O6Y4VM4cMtFrehdg16r6fN/mY8BL\n++kvAi/u59/d/3sEcM3INi+sqkf7UbF/emT5l/uBUB8BPk73e/YC4KqqWtufWjp35LE25xP9drZJ\nXsOYZkmOBF4BvKiqHkhyFfBV4MqqOmFc2x2BDwFjVXVnktOBHfvVr6Z7gf4S8M4kz52eZzC3VdXX\nkzyP7q/aP03y2XFNflyPfVb9Eab2OxbgzVV1xVYoVf/W1XQB8SzgIuD3gAIuHWnzo5HpjEyPv/dg\nsnsRRtfvOG7dDyetdBbzCGP6PQ34fh8W+wMvpHtRvTjJs2HjefLn8NiL7bv9NY0N51W3A/asqs/R\nvfCfBjwZuBb4L32bVwJP7/tfDbwmyU5JnkIXMnoc+lMRD1TVOcAZwPMau14H/Od+evEm2lxBN/LB\n9v1jPSfJLltS7xPYRK/pHwLfT3JE3+Z1wIajjWuA1wLfqKpHge/Rhf4XGh5rUbphirYDju/7fBn4\n+SS7pfv+nhNGHutfk/yHvv2vbPEznUU8wph+nwZOSnIbcDvdG8la4A3Ax5M8qW/3rv6v2b8CbgH+\nhW6MLeiGSzknydPo/hL6QFX9IMkf9dt4HfClvs99VXVjkr+lO5K5e2Q7mrrnAmckeRT4MXAy8L6G\nfm+l22fvpHsNjD+VBXAW3SmsG5OE7nXRcl58ztnMa/rXgaVJdgbuAN7Yt/9W/396dd/uC8DCqvo+\nk1sOLAGeDXyO7lTYo+m+CfRzdL+Dl1bVRX37U+lOS66lu17y5C16srOId3o/gfRh80g/jteLgL+s\nqkNnui5B/wb2YFVVksXACVXll4LNcv0p5N8d/62gc5VHGE8sewF/1x8KP8xjn9DRzHs+sKT/K/cH\nwG/McD3SlHmEIUlq4kVvSVITA0OS1MTAkCQ1MTA05yVZmOSiJN/oxxZ6f7qvBt5U+12T/NbI/DOT\nnD/Fx/zjJK/Ykrql6eZFb81p/aeWrqf7CPJH+puwlgHfq6r/sYk+ewOX9GNJzZhsoyOeatvlx2o1\n170MeKiqPgJQVY8keRvwzSTfBH6B7k76PYBzquqP6Aam27cf8+lK4Ez6AEnyBrqb7XahGwfqfcAO\ndHcd/wh4VVV9rx/B9BLgW3Q37EF3Q+ZB3a0a2bff7gLgAeBNVfW1vt9DwGF0Y49dRDewIXRDUry0\nqu7b+v9NkoEhHUg3SOBGVXVvkm/T/X4sAg6ie9NenuRSujt5D9pwU2R/xDHqILo39B2B1XSjpx6W\n5P8Crwf+YuSxVtCNdkqSM3hs9NtlwElV9Y0kP0c3ptjL+nUbRjx9JMmngN+uqmv74WMe2sL/D2mT\nDAxp866sqnsAklxAN1LphZP0+Vz/V/59SdYBn+qX3wwcPFGHJMfTjUv1yv6N/3DgE90ZMwCeNNJ8\ndMTTa4E/T3IucEFVbWrodGmLGRia626lH9Rxg/57E/aiGzZ+qiOVwr8d9fTRkflHmeB3LslBwOl0\np5Me6e/U/8FmhnXZOOJpVb2nP+p5Fd0pql+oqq811ChNmZ+S0lz3WWDnJK+H7lvvgP8DfJTuNNRR\nSZ6RZCe6axPXAvcBT9kaD55kV7rvWHh9Va2F7pQY3TWUX+3bJMkhm+i/b1XdXFXvpRskb/+tUZc0\nEQNDc1r/3RW/Avxqkm8AX6e7DvAHfZMvA5+k+8KqT1bViv4U1bXpvprzjC0s4Vi672j4qyQ39RfS\nAf4r8Jv9F22t6ttN5K19HSvpRs+9fAvrkTbJj9VKm9B/4mmsqk6Z6Vqk2cAjDElSE48wJElNPMKQ\nJDUxMCRJTQwMSVITA0OS1MTAkCQ1MTAkSU3+P6XpoDbJVITeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6121bd9a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the statistical performanc of the optimizers.\n",
    "fig = plt.figure()\n",
    "st = fig.suptitle(\"Higer is better.\", fontsize=\"x-small\")\n",
    "\n",
    "plt.bar(range(len(results)), results.values(), align='center')\n",
    "plt.xticks(range(len(results)), results.keys())\n",
    "plt.xlabel(\"Optimizers\")\n",
    "plt.ylabel(\"F1\")\n",
    "plt.ylim([0.5,0.6])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
