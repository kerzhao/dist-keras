[TerminalIPythonApp] WARNING | Subcommand `ipython notebook` is deprecated and will be removed in future versions.
[TerminalIPythonApp] WARNING | You likely want to use `jupyter notebook` in the future
[I 02:11:21.771 NotebookApp] Writing notebook server cookie secret to /run/user/1000/jupyter/notebook_cookie_secret
[W 02:11:21.792 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.
[I 02:11:21.871 NotebookApp] Serving notebooks from local directory: /home/ubuntu/gtest/dist-keras
[I 02:11:21.871 NotebookApp] 0 active kernels 
[I 02:11:21.872 NotebookApp] The Jupyter Notebook is running at: http://[all ip addresses on your system]:1427/
[I 02:11:21.872 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 02:11:23.683 NotebookApp] 302 GET / (218.241.251.148) 0.46ms
[I 02:11:23.777 NotebookApp] 302 GET /tree? (218.241.251.148) 0.63ms
[I 02:11:29.843 NotebookApp] 302 POST /login?next=%2Ftree%3F (218.241.251.148) 0.87ms
[W 02:11:52.498 NotebookApp] Notebook examples/workflow.ipynb is not trusted
[I 02:11:53.782 NotebookApp] Kernel started: 66d13bb8-d981-4ec0-8c06-1b8b1578cec5
[W 02:12:04.004 NotebookApp] Timeout waiting for kernel_info reply from 66d13bb8-d981-4ec0-8c06-1b8b1578cec5
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 02:13:54.301 NotebookApp] Saving file at /examples/workflow.ipynb
[W 02:13:54.302 NotebookApp] Saving untrusted notebook examples/workflow.ipynb
[I 02:15:54.113 NotebookApp] Saving file at /examples/workflow.ipynb
[W 02:15:54.114 NotebookApp] Saving untrusted notebook examples/workflow.ipynb
[Stage 2:>                                                          (0 + 2) / 2]                                                                                17/05/10 02:17:19 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[Stage 4:>                                                          (0 + 4) / 4][Stage 4:==============>                                            (1 + 3) / 4]                                                                                [Stage 5:>                                                          (0 + 4) / 4]                                                                                Using TensorFlow backend.
[I 02:17:54.053 NotebookApp] Saving file at /examples/workflow.ipynb
[I 02:18:07.718 NotebookApp] Kernel restarted: 66d13bb8-d981-4ec0-8c06-1b8b1578cec5
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 2:>                                                          (0 + 2) / 2]                                                                                17/05/10 02:18:26 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[Stage 4:>                                                          (0 + 4) / 4][Stage 4:==============>                                            (1 + 3) / 4][Stage 4:============================================>              (3 + 1) / 4]                                                                                [Stage 5:>                                                          (0 + 4) / 4]                                                                                Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
[Stage 10:>                                                         (0 + 4) / 4][Stage 10:==============>                                           (1 + 3) / 4][Stage 10:=============================>                            (2 + 2) / 4][Stage 10:===========================================>              (3 + 1) / 4]                                                                                [I 02:19:54.381 NotebookApp] Saving file at /examples/workflow.ipynb
2017-05-10 02:20:13.041345: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:20:13.041369: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:20:13.041375: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:20:13.041380: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:20:13.041385: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
[Stage 11:>                                                         (0 + 4) / 4][Stage 11:==============>                                           (1 + 3) / 4][Stage 11:=============================>                            (2 + 2) / 4]label
2017-05-10 02:20:58.647605: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:20:58.647642: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:20:58.647648: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:20:58.647652: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:20:58.647655: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
17/05/10 02:20:59 WARN Executor: 1 block locks were not released by TID = 28:
[rdd_58_0]
                                                                                17/05/10 02:21:30 WARN CacheManager: Asked to cache already cached data.
2017-05-10 02:21:30.476338: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:21:30.476529: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:21:30.476597: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:21:30.476651: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:21:30.476681: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
[I 02:21:54.128 NotebookApp] Saving file at /examples/workflow.ipynb
[I 02:23:54.082 NotebookApp] Saving file at /examples/workflow.ipynb
[W 02:25:48.528 NotebookApp] Notebook examples/distributed_numpy_parsing.ipynb is not trusted
[I 02:25:49.026 NotebookApp] Kernel started: d331e3aa-ea22-4708-b69d-9cc4ce0bc06e
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
17/05/10 02:25:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 02:36:25.000 NotebookApp] Kernel restarted: 66d13bb8-d981-4ec0-8c06-1b8b1578cec5
17/05/10 02:36:25 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@6978a201)
17/05/10 02:36:25 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(11,1494383785013,JobFailed(org.apache.spark.SparkException: Job 11 cancelled because SparkContext was shut down))
17/05/10 02:36:25 WARN Executor: 1 block locks were not released by TID = 29:
[rdd_58_0]
17/05/10 02:36:25 ERROR Utils: Uncaught exception in thread stdout writer for python
java.net.SocketException: Socket is closed
	at java.net.Socket.shutdownOutput(Socket.java:1551)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3$$anonfun$apply$4.apply$mcV$sp(PythonRDD.scala:344)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3$$anonfun$apply$4.apply(PythonRDD.scala:344)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3$$anonfun$apply$4.apply(PythonRDD.scala:344)
	at org.apache.spark.util.Utils$.tryLog(Utils.scala:1964)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:344)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)
17/05/10 02:36:25 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@1632f5d8 rejected from java.util.concurrent.ThreadPoolExecutor@37d087c3[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 29]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:372)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:353)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 02:37:54.056 NotebookApp] Saving file at /examples/workflow.ipynb
[I 02:38:40.283 NotebookApp] Kernel restarted: 66d13bb8-d981-4ec0-8c06-1b8b1578cec5
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 02:38:41.618 NotebookApp] Saving file at /examples/workflow.ipynb
[Stage 2:>                                                          (0 + 2) / 2]                                                                                17/05/10 02:38:58 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[Stage 4:>                                                          (0 + 4) / 4][Stage 4:==============>                                            (1 + 3) / 4]                                                                                [Stage 5:>                                                          (0 + 4) / 4][Stage 5:==============>                                            (1 + 3) / 4]                                                                                Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
[Stage 10:>                                                         (0 + 4) / 4][Stage 10:==============>                                           (1 + 3) / 4][I 02:39:53.884 NotebookApp] Saving file at /examples/workflow.ipynb
[Stage 10:=============================>                            (2 + 2) / 4][Stage 10:===========================================>              (3 + 1) / 4]                                                                                2017-05-10 02:40:00.635815: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:40:00.635845: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:40:00.635861: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:40:00.635870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:40:00.635879: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
[Stage 11:>                                                         (0 + 4) / 4][Stage 11:==============>                                           (1 + 3) / 4][Stage 11:=============================>                            (2 + 2) / 4]2017-05-10 02:40:46.469542: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:40:46.469577: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:40:46.469586: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:40:46.469594: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 02:40:46.469601: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
[I 02:41:53.889 NotebookApp] Saving file at /examples/workflow.ipynb
[I 02:47:00.294 NotebookApp] Kernel restarted: 66d13bb8-d981-4ec0-8c06-1b8b1578cec5
17/05/10 02:47:00 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@514ecee4)
17/05/10 02:47:00 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(10,1494384420304,JobFailed(org.apache.spark.SparkException: Job 10 cancelled because SparkContext was shut down))
17/05/10 02:47:00 WARN Executor: 1 block locks were not released by TID = 28:
[rdd_58_0]
17/05/10 02:47:00 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@4d90bf04 rejected from java.util.concurrent.ThreadPoolExecutor@35d41d7b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 28]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1369)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:372)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:353)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 2:>                                                          (0 + 2) / 2]                                                                                17/05/10 02:47:20 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[I 02:47:54.247 NotebookApp] Saving file at /examples/workflow.ipynb
[I 02:49:53.949 NotebookApp] Saving file at /examples/workflow.ipynb
[I 02:53:54.490 NotebookApp] Saving file at /examples/workflow.ipynb
[I 02:55:53.880 NotebookApp] Saving file at /examples/workflow.ipynb
[I 02:57:54.290 NotebookApp] Saving file at /examples/workflow.ipynb
[Stage 22:==============>                                           (1 + 3) / 4]                                                                                [I 02:59:54.149 NotebookApp] Saving file at /examples/workflow.ipynb
[I 03:01:54.236 NotebookApp] Saving file at /examples/workflow.ipynb
[I 03:03:54.315 NotebookApp] Saving file at /examples/workflow.ipynb
[Stage 35:>                                                         (0 + 4) / 4][Stage 35:==============>                                           (1 + 3) / 4]17/05/10 03:05:19 WARN Executor: Managed memory leak detected; size = 4456448 bytes, TID = 249
                                                                                [I 03:05:53.914 NotebookApp] Saving file at /examples/workflow.ipynb
[Stage 37:>                                                         (0 + 4) / 4][Stage 37:==============>                                           (1 + 3) / 4]                                                                                [I 03:06:36.425 NotebookApp] Kernel restarted: 66d13bb8-d981-4ec0-8c06-1b8b1578cec5
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 2:>                                                          (0 + 2) / 2]                                                                                17/05/10 03:07:02 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[Stage 4:>                                                          (0 + 4) / 4][Stage 4:==============>                                            (1 + 3) / 4]                                                                                [I 03:07:53.943 NotebookApp] Saving file at /examples/workflow.ipynb
[I 03:09:54.101 NotebookApp] Saving file at /examples/workflow.ipynb
[I 03:11:54.115 NotebookApp] Saving file at /examples/workflow.ipynb
[I 03:13:54.086 NotebookApp] Saving file at /examples/workflow.ipynb
[I 03:15:54.102 NotebookApp] Saving file at /examples/workflow.ipynb
[I 03:19:54.257 NotebookApp] Saving file at /examples/workflow.ipynb
[I 03:21:54.205 NotebookApp] Saving file at /examples/workflow.ipynb
[I 03:23:54.367 NotebookApp] Saving file at /examples/workflow.ipynb
[I 03:24:09.759 NotebookApp] Kernel restarted: 66d13bb8-d981-4ec0-8c06-1b8b1578cec5
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[Stage 2:>                                                          (0 + 2) / 2]                                                                                17/05/10 03:24:25 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[Stage 4:>                                                          (0 + 4) / 4][Stage 4:==============>                                            (1 + 3) / 4]                                                                                [Stage 5:>                                                          (0 + 4) / 4][Stage 5:============================================>              (3 + 1) / 4]                                                                                [Stage 7:>                                                          (0 + 0) / 4][Stage 7:>                                                          (0 + 4) / 4]                                                                                Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
Using TensorFlow backend.
[Stage 12:>                                                         (0 + 4) / 4][Stage 12:==============>                                           (1 + 3) / 4][Stage 12:=============================>                            (2 + 2) / 4]                                                                                2017-05-10 03:25:50.506579: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 03:25:50.506606: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 03:25:50.506612: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 03:25:50.506617: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 03:25:50.506627: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
[Stage 13:>                                                         (0 + 4) / 4][I 03:25:54.011 NotebookApp] Saving file at /examples/workflow.ipynb
[Stage 13:==============>                                           (1 + 3) / 4][Stage 13:===========================================>              (3 + 1) / 4]2017-05-10 03:26:36.901110: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 03:26:36.901158: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 03:26:36.901171: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 03:26:36.901179: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-10 03:26:36.901187: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
[I 03:26:39.862 NotebookApp] Saving file at /examples/workflow.ipynb
